# Configuration for Crypto Volatility Pipeline

kafka:
  bootstrap_servers: "localhost:9092"
  topic_raw: "ticks.raw"
  topic_features: "ticks.features"
  topic_predictions: "ticks.predictions"
  consumer_group: "volatility-pipeline"
  features_consumer_group: "feature-engine"
  prediction_consumer_group: "volatility-predictor"

coinbase:
  ws_url: "wss://advanced-trade-ws.coinbase.com"
  products:
    - "BTC-USD"  # Bitcoin only
  channels:
    - "ticker"
  heartbeat_interval: 30  # seconds

ingestion:
  data_dir: "data/raw"
  file_format: "ndjson"  # or parquet
  batch_size: 100  # messages before flushing to disk
  reconnect_delay: 5  # seconds
  max_reconnect_attempts: 10

features:
  data_dir: "../data/processed"
  window_size: 300  # seconds (5 minutes lookback)
  prediction_horizon: 60  # seconds (60 seconds ahead)
  min_window_points: 10  # minimum points needed for feature computation
  parquet_batch_size: 1000  # rows before flushing to parquet
  compute_intervals:
    - 1  # 1 second returns
    - 5  # 5 second returns
    - 30  # 30 second returns
    - 60  # 60 second returns

mlflow:
  tracking_uri: "http://localhost:5001"  # Changed from 5000 to avoid macOS Universal Control conflict
  experiment_name: "crypto-volatility-detection"
  artifact_root: "mlruns"  # Local artifact storage

modeling:
  models_dir: "models/artifacts"
  train_ratio: 0.6  # 60% for training
  val_ratio: 0.2    # 20% for validation
  test_ratio: 0.2   # 20% for testing
  threshold_percentile: 85  # Percentile for volatility spike threshold (lowered to get more positive samples)
  baseline_threshold_std: 2.0  # Z-score threshold for baseline model

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

